---
apiVersion: postgresql.cnpg.io/v1
kind: Cluster
metadata:
  name: argo-workflows-postgres
  namespace: argo
spec:
  instances: 2
  storage:
    size: 5Gi
    storageClass: openebs-hostpath
  backup:
    barmanObjectStore:
      destinationPath: s3://backups/argo
      endpointURL: https://s3.infra.server.home:9000
      endpointCA:
        name: homelab-ca
        key: homelab_ca.crt
      # When recovering from WAL or backup, change this value so that the new WAL
      # is written to a new directory in the bucket.
      # serverName: cluster-1
      serverName: cluster-1
      s3Credentials:
        accessKeyId:
          name: s3-creds
          key: ACCESS_KEY_ID
        secretAccessKey:
          name: s3-creds
          key: ACCESS_SECRET_KEY
      wal:
        compression: bzip2
    retentionPolicy: 7d
  # bootstrap:
  #   recovery:
  #     source: argo-workflows-postgres
  # externalClusters:
  #   - name: argo-workflows-postgres
  #     barmanObjectStore:
  #       destinationPath: s3://backups/argo
  #       endpointURL: https://s3.infra.server.home:9000
  #       endpointCA:
  #         name: homelab-ca
  #         key: homelab_ca.crt
  #       # When recovering from WAL or backup, change the value of
  #       # backup.barmanObjectStore.serverName so that the new WAL is written
  #       # to a new directory in the bucket.
  #       serverName: cluster-1
  #       s3Credentials:
  #         accessKeyId:
  #           name: s3-creds
  #           key: ACCESS_KEY_ID
  #         secretAccessKey:
  #           name: s3-creds
  #           key: ACCESS_SECRET_KEY
  #       wal:
  #         maxParallel: 8
---
apiVersion: postgresql.cnpg.io/v1
kind: ScheduledBackup
metadata:
  name: argo-workflows-postgres-backup
  namespace: argo
spec:
  immediate: true
  backupOwnerReference: self
  cluster:
    name: argo-workflows-postgres
  method: barmanObjectStore
  schedule: "0 0 23 * * SUN"
